{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sketch.examples.prompt_machine import *\n",
    "PM_SETTINGS[\"VERBOSE\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test prompt works\n",
    "prompt = asyncGPT3Prompt(\"whitespace_iterations\", \"\"\"{{ head }}{{ body }}\"\"\", temperature=0.0)\n",
    "await prompt(\"      \", \"What is a joke that invovles a hippo?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "async def get_n_samples(N, max_whitepsace_char_N, samples=1, body=\"What is a joke that invovles a hippo?\", request_horizontal_limit=10, temperature=0.0, seed=\"testing-potato\"):\n",
    "    prompt = asyncGPT3Prompt(\"whitespace_iterations\", \"\"\"{{ head }}{{ body }}\"\"\", temperature=temperature)\n",
    "    \n",
    "    def get_random_whitespace_sequence():\n",
    "        sequence = \"\"\n",
    "        for i in range(0, random.randint(0, max_whitepsace_char_N)):\n",
    "            r = random.random()\n",
    "            if r < 0.2:\n",
    "                sequence += \" \"\n",
    "            elif r < 0.3:\n",
    "                sequence += \"\\t\"\n",
    "            elif r < 0.4:\n",
    "                sequence += \"\\n\"\n",
    "        return sequence\n",
    "\n",
    "    \n",
    "    def get_batch():\n",
    "        headers = [get_random_whitespace_sequence() for i in range(0, request_horizontal_limit)]\n",
    "        async def get_wrapped(header):\n",
    "            return (header, await prompt(head=header, body=body))\n",
    "        results = asyncio.gather(*[get_wrapped(header) for header in headers])\n",
    "        return results\n",
    "    \n",
    "    samp = []\n",
    "    for i in range(samples):\n",
    "        random.seed(seed)\n",
    "        results = []\n",
    "        while len(results) < N:\n",
    "            new_results = await get_batch()\n",
    "            for j, (header, result) in enumerate(new_results):\n",
    "                print(f\"==== {len(results)+j:05d}/~{N:05d}\\nHeader:{repr(header)}\\nResult:\\n{repr(result)}\\n====\")\n",
    "                results.append((header, result))\n",
    "        samp.append(results)\n",
    "    return samp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = await get_n_samples(10, 10, samples=1, body=\"What is a joke that invovles a hippo?\", request_horizontal_limit=10, temperature=0.0, seed=\"testing-potato\")\n",
    "print(\"\"\"await get_n_samples(10, 10, samples=1, body=\"What is a joke that invovles a hippo?\", request_horizontal_limit=10, temperature=0.0, seed=\"testing-potato\")\"\"\")\n",
    "print(examples)\n",
    "examples = await get_n_samples(10, 10, samples=1, body=\"What is a joke that invovles a hippo?\", request_horizontal_limit=10, temperature=0.0, seed=\"testing-potato\")\n",
    "print(\"\"\"await get_n_samples(10, 10, samples=1, body=\"What is a joke that invovles a hippo?\", request_horizontal_limit=10, temperature=0.0, seed=\"testing-potato\")\"\"\")\n",
    "print(examples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now with temperature, and no random quoted string at beginning\n",
    "examples = await get_n_samples(10, 0, samples=1, body=\"What is a joke that invovles a hippo?\", request_horizontal_limit=10, temperature=0.7, seed=\"testing-potato\")\n",
    "print(\"\"\"await get_n_samples(10, 0, samples=1, body=\"What is a joke that invovles a hippo?\", request_horizontal_limit=10, temperature=0.7, seed=\"testing-potato\")\"\"\")\n",
    "print(examples)\n",
    "examples = await get_n_samples(10, 0, samples=1, body=\"What is a joke that invovles a hippo?\", request_horizontal_limit=10, temperature=0.7, seed=\"testing-potato\")\n",
    "print(\"\"\"await get_n_samples(10, 0, samples=1, body=\"What is a joke that invovles a hippo?\", request_horizontal_limit=10, temperature=0.7, seed=\"testing-potato\")\"\"\")\n",
    "print(examples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now, do a result against longer headers, no temperature\n",
    "examples = await get_n_samples(20, 200, samples=1, body=\"What is a joke that invovles a hippo?\", request_horizontal_limit=10, temperature=0.0, seed=\"testing-potato\")\n",
    "print(\"\"\"await get_n_samples(20, 200, samples=1, body=\"What is a joke that invovles a hippo?\", request_horizontal_limit=10, temperature=0.0, seed=\"testing-potato\")\"\"\")\n",
    "print(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert a notebook to an html page with outputs kept\n",
    "# jupyter nbconvert --to html --execute random_whitespace_sampling.ipynb\n",
    "! jupyter nbconvert --to html --execute random_whitespace_sampling.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit ('sketch': pyenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "adcb619b33f588203bb576ea56ee3c20c6d0d8de6f18aca777331501d8e7497b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
