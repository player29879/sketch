{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sketch.examples.prompt_machine import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.googleapis.com/customsearch/v1?[parameters]\n",
    "import os\n",
    "import requests\n",
    "\n",
    "google_search_api_key = os.environ.get(\"GOOGLE_SEARCH_API_KEY\", None)\n",
    "google_search_engine_id = os.environ.get(\"GOOGLE_SEARCH_ENGINE_ID\", None)\n",
    "\n",
    "def get_google_response(query):\n",
    "    assert google_search_api_key is not None, \"Must have a GOOGLE_SEARCH_API_KEY (and possibly GOOGLE_SEARCH_ENGINE_ID)\"\n",
    "    assert google_search_engine_id is not None, \"Must have a GOOGLE_SEARCH_ENGINE_ID\"\n",
    "    \n",
    "    response = requests.get(\n",
    "        \"https://www.googleapis.com/customsearch/v1\", params={\"key\": google_search_api_key, \"cx\": \"52cad330ac26249b7\", \"q\": query}\n",
    "    )\n",
    "    return response.json()\n",
    "\n",
    "# LIMITS: 10k/day \n",
    "# also equivalent to ~$50 a day\n",
    "# that's 1 every 8.6s -> or, if burst (2 hours of conversation) -> one every ~0.7 seconds.\n",
    "# hmm, that's not so bad. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = get_google_response(\"things to do northern japan onsen options\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oh this kinda worked already. Just gotta... \"clean\" somehow (??) apply some parsing to simplify the response / compress it\n",
    "# oh, i guess those are \"compression prompts\" (take a prompt of larger size than the output)\n",
    "# \"known compressing prompts\"\n",
    "# and \"known expansion prompts\" \n",
    "# like, it's a \"distribution\" for a given prompt, across the distributions of inputs. \n",
    "# can \"estimate\" the shape of the response in terms of size in terms of tokens.\n",
    "\n",
    "# for something to \"accept\" a 4k+ token input, it must first have likely gone through a compressor.\n",
    "# a compressor is something that \"wants to know where it came from\" (typing information is useful for a compressor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit ('sketch': pyenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "adcb619b33f588203bb576ea56ee3c20c6d0d8de6f18aca777331501d8e7497b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
