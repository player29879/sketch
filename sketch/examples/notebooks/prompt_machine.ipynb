{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import websockets\n",
    "import json\n",
    "import asyncio\n",
    "import sqlite3\n",
    "import requests\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "oopenai_api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "BOT_TOKEN = \"5a3556bb2de44a73ab2e5643cb633a6c\"\n",
    "THREAD_ID = \"default\"\n",
    "DB_PATH = '../datasets/nba_sql.db'\n",
    "uri = f\"wss://www.approx.dev/ws/chat?thread_id={THREAD_ID}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gpt3_response(prompt, stop=None):\n",
    "    headers = {\"Authorization\": f\"Bearer {oopenai_api_key}\", \"Content-Type\": \"application/json\"}\n",
    "    data = {\"prompt\": prompt, \"max_tokens\": 500, \"temperature\": 0, \"model\": \"text-davinci-002\"}\n",
    "    if stop:\n",
    "        data[\"stop\"] = stop\n",
    "    response = requests.post(\"https://api.openai.com/v1/completions\", headers=headers, json=data)\n",
    "    return response.json()[\"choices\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def chatbot_messages():\n",
    "    uri = f\"ws://localhost:8000/ws/chat?thread_id={THREAD_ID}\"\n",
    "    messages = []\n",
    "    async with websockets.connect(uri, extra_headers={\"Cookie\": f\"Authorization=Bearer {BOT_TOKEN}\"}) as ws:\n",
    "        while True:\n",
    "            try:\n",
    "                raw_data = await asyncio.wait_for(ws.recv(), timeout=0.5)\n",
    "                data = json.loads(raw_data)\n",
    "                if data.get(\"replay\", False):\n",
    "                    messages.append(data)\n",
    "                    continue\n",
    "            except:\n",
    "                break\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from databases import Database\n",
    "import uuid\n",
    "\n",
    "MIGRATION_VERSION_TABLE = \"mochaver\"\n",
    "\n",
    "\n",
    "async def table_exists(db: Database, table_name: str):\n",
    "    query = \"SELECT name FROM sqlite_master WHERE type='table' AND name=:table_name;\"\n",
    "    result = await db.fetch_one(query, values={\"table_name\": table_name})\n",
    "    return result is not None\n",
    "\n",
    "\n",
    "async def get_migration_version(db: Database):\n",
    "    if await table_exists(db, MIGRATION_VERSION_TABLE):\n",
    "        version_query = f\"SELECT version FROM {MIGRATION_VERSION_TABLE};\"\n",
    "        (result,) = await db.fetch_one(version_query)\n",
    "        return result\n",
    "    return None\n",
    "\n",
    "\n",
    "async def set_version(db: Database, version: int):\n",
    "    query = f\"UPDATE {MIGRATION_VERSION_TABLE} SET version = :version;\"\n",
    "    await db.execute(query, values={\"version\": version})\n",
    "\n",
    "\n",
    "MIGRATIONS = {}\n",
    "\n",
    "\n",
    "async def setup_database(db: Database):\n",
    "    async with db.transaction():\n",
    "        # check if table exists for \"migration_version\"\n",
    "        migration_version = await get_migration_version(db)\n",
    "        for _, migration in sorted(MIGRATIONS.items(), key=lambda x: x[0]):\n",
    "            await migration(db, migration_version)\n",
    "\n",
    "\n",
    "def migration(version: int):\n",
    "    def decorator(func):\n",
    "        async def run_migration(db: Database, db_version: int):\n",
    "            if db_version is None or db_version < version:\n",
    "                print(\"Running migration\", version)\n",
    "                await func(db)\n",
    "                await set_version(db, version)\n",
    "\n",
    "        MIGRATIONS[version] = run_migration\n",
    "        return run_migration\n",
    "\n",
    "    return decorator\n",
    "\n",
    "@migration(0)\n",
    "async def migration_0(db: Database):\n",
    "    create_migration_table = f\"\"\"\n",
    "        CREATE TABLE {MIGRATION_VERSION_TABLE} (\n",
    "            version INTEGER NOT NULL PRIMARY KEY\n",
    "        ) WITHOUT ROWID;\n",
    "    \"\"\"\n",
    "    await db.execute(create_migration_table)\n",
    "    await db.execute(f\"INSERT INTO {MIGRATION_VERSION_TABLE} (version) VALUES (0);\")\n",
    "\n",
    "\n",
    "\n",
    "@migration(1)\n",
    "async def migration_1(db: Database):\n",
    "    queries = [\n",
    "        \"\"\"\n",
    "        CREATE TABLE promptHistory (\n",
    "            id TEXT NOT NULL PRIMARY KEY,\n",
    "            prompt_id TEXT NOT NULL,\n",
    "            prompt_name TEXT NOT NULL,\n",
    "            inputs TEXT NOT NULL,\n",
    "            response TEXT NOT NULL,\n",
    "            duration REAL NOT NULL,\n",
    "            timestamp TEXT NOT NULL\n",
    "        ) WITHOUT ROWID;\n",
    "        \"\"\",\n",
    "    ]\n",
    "    for query in queries:\n",
    "        await db.execute(query)\n",
    "\n",
    "\n",
    "async def record_prompt(db: Database, prompt_id, prompt_name, inputs, response, duration):\n",
    "    query = \"\"\"\n",
    "        INSERT INTO promptHistory (id, prompt_id, prompt_name, inputs, response, duration, timestamp)\n",
    "        VALUES (:id, :prompt_id, :prompt_name, :inputs, :response, :duration, datetime());\n",
    "    \"\"\"\n",
    "    await db.execute(\n",
    "        query,\n",
    "        values={\n",
    "            \"id\": str(uuid.uuid4()),\n",
    "            \"prompt_id\": prompt_id,\n",
    "            \"prompt_name\": prompt_name,\n",
    "            \"inputs\": json.dumps(inputs),\n",
    "            \"response\": response,\n",
    "            \"duration\": duration,\n",
    "        },\n",
    "    )\n",
    "\n",
    "async def get_prompts(db: Database, prompt_name: str, n=5):\n",
    "    query = f\"\"\"\n",
    "        SELECT inputs, response FROM promptHistory\n",
    "        WHERE prompt_name = :prompt_name\n",
    "        ORDER BY timestamp DESC\n",
    "        LIMIT {n};\n",
    "    \"\"\"\n",
    "    result = await db.fetch_all(query, values={\"prompt_name\": prompt_name})\n",
    "    return [(json.loads(inputs), response) for inputs, response in result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from re import S\n",
    "from jinja2 import Environment, meta\n",
    "import time\n",
    "import inspect\n",
    "from hashlib import md5\n",
    "\n",
    "database = Database(\"sqlite+aiosqlite:///promptHistory.db\")\n",
    "await setup_database(database)\n",
    "env = Environment()\n",
    "\n",
    "\n",
    "class Prompt:\n",
    "    # prompts are functions that take in inputs and output strings\n",
    "    def __init__(self, name, function=None):\n",
    "        self.name = name\n",
    "        self.function = function\n",
    "\n",
    "    def execute(self, *args, **kwargs):\n",
    "        if self.function is None:\n",
    "            raise NotImplementedError(\"Must implement function\")\n",
    "        return self.function(*args, **kwargs)\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        st = time.time()\n",
    "        response = self.execute(*args, **kwargs)\n",
    "        et = time.time()\n",
    "        asyncio.create_task(\n",
    "            record_prompt(database, self.id, self.name, {'args': args, 'kwargs': kwargs}, response, et - st)\n",
    "        )\n",
    "        return response\n",
    "\n",
    "    @property\n",
    "    def id(self):\n",
    "        # grab the code from execute method and hash it\n",
    "        return md5(inspect.getsource(self.function).encode('utf-8')).hexdigest()\n",
    "\n",
    "# https://zetcode.com/python/jinja/\n",
    "class GPT3Prompt(Prompt):\n",
    "    def __init__(self, name, prompt_template_string, stop=None):\n",
    "        super().__init__(name)\n",
    "        self.prompt_template_string = prompt_template_string\n",
    "        self.prompt_template = env.from_string(prompt_template_string)\n",
    "        self.stop = stop\n",
    "\n",
    "    def get_named_args(self):\n",
    "        return meta.find_undeclared_variables(env.parse(self.prompt_template_string))\n",
    "\n",
    "    def get_prompt(self, **kwargs):\n",
    "        return self.prompt_template.render(**kwargs)\n",
    "\n",
    "    def execute(self, **kwargs):\n",
    "        prompt = self.get_prompt(**kwargs)\n",
    "        response = get_gpt3_response(prompt, self.stop)\n",
    "        return response\n",
    "\n",
    "    @property\n",
    "    def id(self):\n",
    "        # grab the code from execute method and hash it\n",
    "        return md5(self.prompt_template_string.encode('utf-8')).hexdigest()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isSQLyn = GPT3Prompt(\"isSQLyn\",\n",
    "\"\"\"\n",
    "The following is a conversation with a data expert (datAI). \n",
    "In order to respond to the prompt, should the datAI use SQL or just say something friendly in response?\n",
    "The users intent: {{ userIntent }}\n",
    "===\n",
    "{{ conversation }}\n",
    "===\n",
    "The datAI should use SQL to answer the question (y/n):\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isSQLyn(userIntent=\"I want to know how many people are in the database\", conversation=\"Hi there\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlExecutor = GPT3Prompt(\"sqlExecutor\",\n",
    "\"\"\"\n",
    "The following is a conversation with a data expert (datAI). In order to be accurate, datAI would like to use SQL. \n",
    "There is a sqlite database (nba.sql)\n",
    "UserIntent: {{userIntent}}\n",
    "---\n",
    "|| Database Context ||\n",
    "{{ database_context }}\n",
    "===\n",
    "{{ conversation }}\n",
    "===\n",
    "{% if previousAttempt %}\n",
    "The AI has tried already but failed: Previous Query and response\n",
    "{{ previousAttempt }}\n",
    "---\n",
    "New Attempt that is different\n",
    "{% endif %}\n",
    "The SQLite query that datAI would like to execute is:\n",
    "```\"\"\"\n",
    ", stop=\"```\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gotAValidSQLResponse = GPT3Prompt(\"gotAValidSQLResponse\",\n",
    "\"\"\"\n",
    "===\n",
    "{{ conversation }}\n",
    "===\n",
    "In order to answer a question (above), a data expert (datAI) executed the following SQL query:\n",
    "{{ sql }}\n",
    "And the result of the execution was:\n",
    "{{ result }}\n",
    "===\n",
    "Did the query execute successfully (y/n):\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "composeDataDrivenAnswer = GPT3Prompt(\"composeDataDrivenAnswer\",\n",
    "\"\"\"\"\n",
    "The following is a conversation with a data expert (datAI). In order to be accurate, the data expert used a database (queried with SQL).\n",
    "===\n",
    "{{ conversation }}\n",
    "===\n",
    "The query and response:\n",
    "{{ sql }}\n",
    "Result:\n",
    "{{ result }}\n",
    "===\n",
    "What should datAI say in response to the last message summarizing what it ran and its result (it can just directly copy if that is the best answer)?\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neededHelpButStillFriendly = GPT3Prompt(\"neededHelpButStillFriendly\",\n",
    "\"\"\"\n",
    "The following is a conversation with a friendly chatbot (datAI, a data expert), who loves basketball.\n",
    "The dataAI tried to run some SQL, but failed to get a good response to the question, \n",
    "and now wants to ask a clarifying question so that it can query the database better to help the user...\n",
    "===\n",
    "{{ conversation }}\n",
    "datAI:\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "friendlyChatbot = GPT3Prompt(\"friendlyChatbot\",\n",
    "\"\"\"\n",
    "The following is a conversation with a friendly chatbot (datAI, a data expert), who loves basketball.\n",
    "The response will never contain a data response unless it has proof in the form of executed SQL. \n",
    "datAI does not respond with guesses, so will ask questions to clarify the users intent to help it formulate a SQL query.\n",
    "datAI never repeats itself either.\n",
    "userIntent: {{ userIntent }}\n",
    "===\n",
    "{{ conversation }}\n",
    "datAI:\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkIfNeedsSQL = GPT3Prompt(\"checkIfNeedsSQL\",\n",
    "\"\"\"\n",
    "The following is a conversation with a friendly chatbot (datAI, a data expert), who loves basketball.\n",
    "Does the following statement contain any attempt at factual information that would exist in a database?\n",
    "\n",
    "Statement: {{ statement }}\n",
    "===\n",
    "y/n:\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getUserIntent = GPT3Prompt(\"getUserIntent\",\n",
    "\"\"\"\n",
    "The following is a conversation with a friendly chatbot (datAI, a data expert).\n",
    "===\n",
    "{{ conversation }}\n",
    "===\n",
    "What is the users intent in this conversation?\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def starts_with_y(string_data):\n",
    "    return string_data.strip().lower()[:1] == 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_sql(sql, response_limit=500):\n",
    "    try:\n",
    "        conn = sqlite3.connect(DB_PATH) \n",
    "        c = conn.cursor()\n",
    "        c.execute(sql)\n",
    "        res = str(c.fetchall())[:response_limit]\n",
    "    except Exception as e:\n",
    "        res = f\"Error executing SQL {e}\"\n",
    "    return res\n",
    "\n",
    "exec_sql = Prompt(\"exec_sql\", execute_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(DB_PATH) \n",
    "c = conn.cursor()\n",
    "# execute a sql query to get all the tables and the columns in the tables\n",
    "c.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "outputschema = \"\"\n",
    "for table, in c.fetchall():\n",
    "    outputschema += table + \"(\"\n",
    "    c.execute(f\"PRAGMA table_info({table})\")\n",
    "    for _, column, dtype, *_ in c.fetchall():\n",
    "        outputschema += f\" {column} \"\n",
    "    outputschema += \") \\n\"\n",
    "    output = c.execute(f\"select * from {table} limit 1\").fetchall()\n",
    "    if len(output) == 0:\n",
    "        outputschema += \"Empty Table\"\n",
    "    else:\n",
    "        outputschema += \" \".join([str(x) for x in output[0]])\n",
    "    outputschema += \"\\n\"\n",
    "database_context = outputschema + \"Example Query (Russell Westbrook's total Triple-Doubles)\\n\"\n",
    "database_context += \"\"\"\n",
    "SELECT SUM(td3) \n",
    "FROM player_game_log \n",
    "LEFT JOIN player ON player.player_id = player_game_log.player_id \n",
    "WHERE player.player_name = 'Russell Westbrook';\n",
    "=========\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def example_promptchain(conversation):\n",
    "    userIntent = getUserIntent(conversation=conversation)\n",
    "    shouldUseSQL = isSQLyn(conversation=conversation, userIntent=userIntent)\n",
    "    answer = friendlyChatbot(userIntent=userIntent, conversation=conversation)\n",
    "    needsSql = checkIfNeedsSQL(statement=answer)\n",
    "    trials = 0\n",
    "    if starts_with_y(shouldUseSQL) or starts_with_y(needsSql):\n",
    "        previousAttempt = None\n",
    "        while trials < 3:\n",
    "            sqlresponse = sqlExecutor(userIntent=userIntent, conversation=conversation, previousAttempt=previousAttempt, database_context=database_context)\n",
    "            res = exec_sql(sqlresponse)\n",
    "            validSQL = gotAValidSQLResponse(conversation=conversation, sql=sqlresponse, result=res)\n",
    "            if starts_with_y(validSQL):\n",
    "                return composeDataDrivenAnswer(conversation=conversation, sql=sqlresponse, result=res)\n",
    "            trials += 1\n",
    "            previousAttempt = f\"```{sqlresponse}```\\nResult:{res[:100]}\\n\"\n",
    "        return neededHelpButStillFriendly(conversation=conversation)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epc = Prompt(\"example_promptchain\", example_promptchain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epc(\"Justin: Who won the most games in 2016?\\nDatAI:The query ran was:\\n\\nSELECT team_id_winner, COUNT(*) as num_wins\\nFROM game\\nWHERE season_id = 2016\\nGROUP BY team_id_winner\\nORDER BY num_wins DESC\\nLIMIT 1;\\n\\nThe result was:\\n\\n[(1610612744, 67)]\\nJustin:What team is 1610612744?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def chatbot():\n",
    "    messages = []\n",
    "    async with websockets.connect(uri, extra_headers={\"Cookie\": f\"Authorization=Bearer {BOT_TOKEN}\"}) as ws:\n",
    "        while True:\n",
    "            try:\n",
    "                raw_data = await asyncio.wait_for(ws.recv(), timeout=0.5)\n",
    "                data = json.loads(raw_data)\n",
    "                print(\"log:\", data['message'])\n",
    "                if data.get(\"replay\", False) or data[\"sender\"] == \"datAI\":\n",
    "                    messages.append(data)\n",
    "                    continue\n",
    "                if data[\"message\"] == \"break\":\n",
    "                    break\n",
    "                if data.get(\"meta\", False):\n",
    "                    continue\n",
    "                messages.append(data)\n",
    "            except asyncio.TimeoutError:\n",
    "                # not sure why I'm doing this, it felt important to have an \"infinite\" loop...\n",
    "                continue\n",
    "            response = epc(\"\\n\".join([f\"{m['sender']}: {m['message']}\" for m in messages]))\n",
    "            await ws.send(json.dumps({\"message\": response}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await chatbot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# messages = await chatbot_messages()\n",
    "# response = example_promptchain(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thing = await get_prompts(database, \"sqlExecutor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(thing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlExecutor_test = GPT3Prompt(\"sqlExecutor_test\",\n",
    "\"\"\"\n",
    "The following is a conversation with a data expert (datAI). In order to be accurate, datAI would like to use SQL. \n",
    "There is a sqlite database (nba.sql)\n",
    "UserIntent: {{userIntent}}\n",
    "===\n",
    "{{ conversation }}\n",
    "===e`\n",
    "The SQLite query that datAI would like to execute is:\n",
    "```\"\"\"\n",
    ", stop=\"```\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for t_in, t_out in thing:\n",
    "#     print(f\"Was: {t_out}, now is: {sqlExecutor_test(**t_in['kwargs'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit ('sketch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "1a56c398c352595db7d0130f0fc00eb36e63ee8641ddc16c2e5bdd38e08d5e9b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
