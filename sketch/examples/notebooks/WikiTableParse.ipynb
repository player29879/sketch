{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = '/media/share/DataSaves/wikitable_extract_220814_test'\n",
    "directory = '/Volumes/14TB/DataSaves/wikitable_extract_220814_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "test = glob.glob(directory + '/*.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "265"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip inst?all py-wikimarkup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wikimarkup.parser import Parser\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "parser = Parser()\n",
    "\n",
    "def get_tables(markdowntext):\n",
    "    output = []\n",
    "    try:\n",
    "        html = parser.parse(markdowntext)\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        tables = soup.find_all('table')\n",
    "        df_tables = pd.read_html(html)\n",
    "        if len(tables) != len(df_tables):\n",
    "            print(\"tables offset..\")\n",
    "            return []\n",
    "        output = []\n",
    "        for i, table in enumerate(tables):\n",
    "            # all previous headings in order\n",
    "            headings = []\n",
    "            for k in range(6):\n",
    "                h = table.find_previous_sibling(f'h{k}')\n",
    "                headings.append(\n",
    "                    h.text if h else ''\n",
    "                )\n",
    "            output.append((i, \"\\n\".join(headings), df_tables[i]))\n",
    "    except Exception as e:\n",
    "        print(\"Failed to parse...\")\n",
    "    return output\n",
    "\n",
    "def get_all_tables(path):\n",
    "    data = pd.read_parquet(path)\n",
    "    data = data['page_text'].groupby(data['page_title_text']).first()\n",
    "    for title, text in data.iteritems():\n",
    "        result = get_tables(text)\n",
    "        for row in result:\n",
    "            yield title, *row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sketch import Portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 /Volumes/14TB/DataSaves/wikitable_extract_220814_test/11771.parquet\n",
      "0 26.573625802993774\n",
      "About to upload... 2\n",
      "Failed to parse...\n",
      "Failed to parse...\n",
      "Failed to parse...\n",
      "100 29.744261980056763\n",
      "About to upload... 524\n",
      "200 37.14842700958252\n",
      "About to upload... 514\n",
      "Failed to parse...\n",
      "300 44.4172739982605\n",
      "About to upload... 616\n",
      "Failed to parse...\n",
      "Failed to parse...\n",
      "Failed to parse...\n",
      "400 52.819101095199585\n",
      "About to upload... 487\n",
      "Failed to parse...\n",
      "500 61.81754493713379\n",
      "About to upload... 521\n",
      "Failed to parse...\n",
      "Failed to parse...\n",
      "Failed to parse...\n",
      "600 68.66260313987732\n",
      "About to upload... 547\n",
      "tables offset..\n",
      "Failed to parse...\n",
      "700 76.20478296279907\n",
      "About to upload... 460\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "st = time.time()\n",
    "results = []\n",
    "for k, thing in enumerate(test[0:50]):\n",
    "    print(k, thing)\n",
    "    for i, x in enumerate(get_all_tables(thing)):\n",
    "        results.append(x)\n",
    "        if i%100 == 0:\n",
    "            print(i, time.time() - st)\n",
    "            pf = Portfolio()\n",
    "            for result in results:\n",
    "                pf.add_wikitable(result[0], result[1], result[2], result[3])\n",
    "            print(f\"About to upload... {len(pf.sketchpads)}\")\n",
    "            pf.upload(apiKey=\"8f79be2b6d0d47ccb8192e46f38c80ce\")\n",
    "            results = []\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit ('sketch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1a56c398c352595db7d0130f0fc00eb36e63ee8641ddc16c2e5bdd38e08d5e9b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
