{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sketch.examples.prompt_machine import *\n",
    "\n",
    "async def chatbot(response_callback):\n",
    "    messages = []\n",
    "    async with websockets.connect(PM_SETTINGS['uri'], extra_headers={\"Cookie\": f\"Authorization=Bearer {PM_SETTINGS['BOT_TOKEN']}\"}) as ws:\n",
    "        while True:\n",
    "            try:\n",
    "                raw_data = await asyncio.wait_for(ws.recv(), timeout=0.5)\n",
    "                data = json.loads(raw_data)\n",
    "                print(\"log:\", data)\n",
    "                if data.get(\"replay\", False) or data[\"sender\"] == \"datAI\":\n",
    "                    messages.append(data)\n",
    "                    continue\n",
    "                if data[\"message\"] == \"break\":\n",
    "                    break\n",
    "                if data.get(\"meta\", False):\n",
    "                    continue\n",
    "                messages.append(data)\n",
    "            except asyncio.TimeoutError:\n",
    "                # not sure why I'm doing this, it felt important to have an \"infinite\" loop...\n",
    "                continue\n",
    "            conversation = \"\\n\".join([f\"{m['sender']}: {m['message']}\" for m in messages[-10:]])\n",
    "            response = response_callback(conversation)\n",
    "            await ws.send(json.dumps({\"message\": response}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PM_SETTINGS['uri']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "respond = GPT3Prompt(\"basic_response\", \"\"\"\n",
    "this is a conversation between a human and a dog\n",
    "{{conversation}}\n",
    "dog:\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "def basic_talker(conversation):\n",
    "    response = respond(conversation)\n",
    "    if len(response) > 10:\n",
    "        response = \"LONG RESPONSE\" + response\n",
    "    return response\n",
    "\n",
    "convo = Prompt(\"basic_convo\", basic_talker)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await chatbot(convo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit ('paradise': pyenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "7dae0a206a64955a141419f497d324bd66be1bc88c004fc546eea65c32731a92"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
