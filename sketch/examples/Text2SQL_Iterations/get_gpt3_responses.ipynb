{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data = json.load(open(\"spider_train.json\"))\n",
    "for i, row in enumerate(data):\n",
    "    row['row_id'] = f\"spider_train|{i}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data_eval = json.load(open(\"spider_eval.json\"))\n",
    "for i, row in enumerate(data):\n",
    "    row['row_id'] = f\"spider_eval|{i}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spider_input = json.load(open(\"spider/train_spider.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "API_KEY = # GET THIS FROM SOMEONE.\n",
    "\n",
    "def get_gpt3_response(prompt):\n",
    "    headers = {\"Authorization\": f\"Bearer {API_KEY}\", \"Content-Type\": \"application/json\"}\n",
    "    data = {\"prompt\": prompt, \"max_tokens\": 200, \"temperature\": 0, \"model\": \"text-davinci-002\"}\n",
    "    response = requests.post(\"https://api.openai.com/v1/completions\", headers=headers, json=data)\n",
    "    return response.json()\n",
    "\n",
    "def line_prompt(row, answer=None):\n",
    "    return f\"Question: {row['text_in']};\\nSchema Information: {row['struct_in']};\\nSQL:\" + (f\"{answer}\\n\" if answer else \"\")\n",
    "\n",
    "def get_preprompt(ids):\n",
    "    return '\\n'.join([line_prompt(data[id], data[id]['query'])+\"\\n\" for id in ids])\n",
    "\n",
    "preprompt123 = get_preprompt([123, 456, 1516, 1522])\n",
    "def get_prompt(row):\n",
    "    return preprompt123 + line_prompt(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_prompt(data[1555]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare executed results\n",
    "def get_result(db_name, sql):\n",
    "    import sqlite3\n",
    "    conn = sqlite3.connect(f\"spider/database/{db_name}/{db_name}.sqlite\")\n",
    "    conn.text_factory = lambda b: b.decode(errors=\"ignore\")\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(sql)\n",
    "    return cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_a_row(row, verbose=True):\n",
    "    prompt = get_prompt(row)\n",
    "\n",
    "    # print(\"PROMPT USED FOR GPT3\")\n",
    "    # print(prompt)\n",
    "    # print(\"-------------------\")\n",
    "\n",
    "    try:\n",
    "        gpt3_answer = get_gpt3_response(prompt).get('choices', [{'text': \"COMPLETION_ERROR\"}])[0]['text']\n",
    "        # gpt3_answer = \"wow, this is a great answer\"\n",
    "    except:\n",
    "        gpt3_answer = \"Something failed in querying openai\"\n",
    "    query_answer = row['query']\n",
    "    seq_out_answer = row['seq_out']\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Question: \", row['question'])\n",
    "        print(\"GOLD: \", query_answer)\n",
    "        print(\"GPT3: \", gpt3_answer)\n",
    "        print(\"SEQ_OUT: \", seq_out_answer)\n",
    "\n",
    "    try:\n",
    "        real_data = get_result(row['db_id'], query_answer)\n",
    "    except:\n",
    "        real_data = \"EXECUTION ERROR\"\n",
    "    # attempt to run all 3 and get data\n",
    "    try:\n",
    "        gpt3_data = get_result(row['db_id'], gpt3_answer)\n",
    "    except:\n",
    "        gpt3_data = \"EXECUTION ERROR\"\n",
    "    try:\n",
    "        seq_out_data = get_result(row['db_id'], seq_out_answer)\n",
    "    except:\n",
    "        seq_out_data = \"EXECUTION ERROR\"\n",
    "    if verbose:\n",
    "        print(\"REAL: \", real_data)\n",
    "        print(\"GPT3: \", gpt3_data)\n",
    "        print(\"T5: \", seq_out_data)\n",
    "    sql = {'query_answer': query_answer, 'gpt3_answer': gpt3_answer, 'seq_out_answer': seq_out_answer}\n",
    "    return sql, (real_data, gpt3_data, seq_out_data)\n",
    "\n",
    "def get_scores(real_data, gpt3_data, seq_out_data):\n",
    "    scores = {}\n",
    "    scores['gpt3_correct'] = gpt3_data == real_data\n",
    "    scores['seq_out_correct'] = seq_out_data == real_data\n",
    "    scores['gpt3_executed'] = gpt3_data != \"EXECUTION ERROR\"\n",
    "    scores['seq_out_executed'] = seq_out_data != \"EXECUTION ERROR\"\n",
    "    scores['query_executed'] = real_data != \"EXECUTION ERROR\"\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "def get_result_run(dataset):\n",
    "    all_results = []\n",
    "    print(f\"{len(dataset)}\")\n",
    "    for i, row in enumerate(dataset):\n",
    "        sql, results = run_a_row(row, verbose=False)\n",
    "        scores = get_scores(*results)\n",
    "        all_results.append({'id': row['row_id'], **sql, **scores})\n",
    "        if i % (len(dataset) // 10) == 0:\n",
    "            print(f\"{i} done\")\n",
    "    return pd.DataFrame(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_result_run(random.sample(data, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Ran for {} rows\".format(len(df)))\n",
    "print(df.seq_out_correct.mean()*100, \"% of seq_out_correct\")\n",
    "print(df.seq_out_executed.mean()*100, \"% of seq_out_executed\")\n",
    "print(df.gpt3_correct.mean()*100, \"% of gpt3_correct\")\n",
    "print(df.gpt3_executed.mean()*100, \"% of gpt3_executed\")\n",
    "print(df.query_executed.mean()*100, \"% of query_executed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.rename(columns={'t5_answer': 'seq_out_answer'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"gpt3_results.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.gpt3_answer == 'COMPLETION_ERROR').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    thing = df[df['gpt3_correct'] == False].sample()\n",
    "    failed_result = thing.reset_index().iloc[0].to_dict()\n",
    "    failed_row = data[int(failed_result['id'].split('|')[1])]\n",
    "    print(\"Question: \", failed_row['question'])\n",
    "\n",
    "    print(\"GPT3 Query:\", failed_result['gpt3_answer'])\n",
    "    print(\"GOLD Query:\", failed_result['query_answer'])\n",
    "\n",
    "    try:\n",
    "        r1 = get_result(failed_row['db_id'], failed_result['gpt3_answer'])\n",
    "        if len(r1) > 10:\n",
    "            r1 = r1[:10]\n",
    "            print(\"Truncating GPT3 response\")\n",
    "        print(\"GPT3 QueryResult:\", r1)\n",
    "    except Exception as e:\n",
    "        print(\"GPT3 QueryFAILED:\", e)\n",
    "    r2 = get_result(failed_row['db_id'], failed_result['query_answer'])\n",
    "    if len(r2) > 10:\n",
    "        r2 = r2[:10]\n",
    "        print(\"Truncating GOLD response\")\n",
    "    print(\"GOLD QueryResult:\", r2)\n",
    "    print(\"========================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[1549]['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = get_gpt3_response(get_prompt(data[555]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_parquet(\"GPT3_vs_T5.parquet\")['gpt3_correct'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "31/44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[555]['query']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[555]['seq_out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit ('sketch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "1a56c398c352595db7d0130f0fc00eb36e63ee8641ddc16c2e5bdd38e08d5e9b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
