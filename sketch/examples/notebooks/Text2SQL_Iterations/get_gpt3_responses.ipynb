{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from sketch.examples.prompt_machine import *\n",
    "import json\n",
    "import os\n",
    "import sqlite3\n",
    "import random\n",
    "\n",
    "PM_SETTINGS[\"VERBOSE\"] = False\n",
    "SPIDER_DB_PATH = \"/home/jawaugh/benchmarks/raw/spider/spider/database/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def download_file_from_google_drive(id, destination):\n",
    "#     URL = \"https://docs.google.com/uc?export=download\"\n",
    "\n",
    "#     session = requests.Session()\n",
    "\n",
    "#     response = session.get(URL, params = { 'id' : id }, stream = True)\n",
    "#     token = get_confirm_token(response)\n",
    "\n",
    "#     if token:\n",
    "#         params = { 'id' : id, 'confirm' : token }\n",
    "#         response = session.get(URL, params = params, stream = True)\n",
    "\n",
    "#     save_response_content(response, destination)    \n",
    "\n",
    "# def get_confirm_token(response):\n",
    "#     for key, value in response.cookies.items():\n",
    "#         if key.startswith('download_warning'):\n",
    "#             return value\n",
    "\n",
    "#     return None\n",
    "\n",
    "# def save_response_content(response, destination):\n",
    "#     CHUNK_SIZE = 32768\n",
    "\n",
    "#     with open(destination, \"wb\") as f:\n",
    "#         for chunk in response.iter_content(CHUNK_SIZE):\n",
    "#             if chunk: # filter out keep-alive new chunks\n",
    "#                 f.write(chunk)\n",
    "\n",
    "# download_file_from_google_drive(\"1m_M2VOjM7Xxq0z9hxgGdYIGIKhxOIU-F\", \"spider_train.json\")\n",
    "# download_file_from_google_drive(\"1twy32bdOYcTY8HXrISm1vTBMMjTzI9Fa\", \"spider_eval.json\")\n",
    "\n",
    "data = json.load(open(\"spider_train.json\"))\n",
    "for i, row in enumerate(data):\n",
    "    row['row_id'] = f\"spider_train|{i}\"\n",
    "\n",
    "data_eval = json.load(open(\"spider_eval.json\"))\n",
    "for i, row in enumerate(data):\n",
    "    row['row_id'] = f\"spider_eval|{i}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare executed results\n",
    "\n",
    "def get_result(db_name, sql):\n",
    "    conn = sqlite3.connect(os.path.join(SPIDER_DB_PATH, f\"{db_name}/{db_name}.sqlite\"))\n",
    "    conn.text_factory = lambda b: b.decode(errors=\"ignore\")\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(sql)\n",
    "    return cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_database_context(db_name):\n",
    "    db_path = os.path.join(SPIDER_DB_PATH, f\"{db_name}/{db_name}.sqlite\")\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    # execute a sql query to get all the tables and the columns in the tables\n",
    "    c.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    outputschema = \"\"\n",
    "    # outputschema = \"Example: table.column* (row1 value) *means join key\\n\"\n",
    "    for (table,) in c.fetchall():\n",
    "        # # # STYLE 2\n",
    "        # outputschema += f\"===== {table} =====\\n\"\n",
    "        # c.execute(f\"PRAGMA table_info({table})\")\n",
    "        # column_names = [column for _, column, dtype, *_ in c.fetchall()]\n",
    "        # output = c.execute(f\"select * from {table} limit 2\").fetchall()\n",
    "        # for i, column in enumerate(column_names):\n",
    "        #     if len(output) == 0:\n",
    "        #         outputschema += f\"{column} : -empty-\"\n",
    "        #     elif len(output) == 1:\n",
    "        #         outputschema += f\"{column} : {output[0][i]}\"\n",
    "        #     else:\n",
    "        #         outputschema += f\"{column} : {output[0][i]} | {output[1][i]}\"\n",
    "        #     outputschema += \"\\n\"\n",
    "\n",
    "        # # STYLE 1\n",
    "        outputschema += f\"{table} (\"\n",
    "        fks = [(tab, fro, to) for _, _, tab, fro, to, *_ in c.execute(f\"PRAGMA foreign_key_list({table})\").fetchall()]\n",
    "        cols_to_star = [co for _, co, _ in fks]\n",
    "        c.execute(f\"PRAGMA table_info({table})\")\n",
    "        columns = [column + (\"*\" if pk or column in cols_to_star else \"\") for _, column, dtype, _, _, pk in c.fetchall() ]\n",
    "        outputschema += \"|\".join(columns)\n",
    "        outputschema += \") \\n\"\n",
    "        output = c.execute(f\"select * from {table} limit 2\").fetchall()\n",
    "        if len(output) == 0:\n",
    "            outputschema += \"Empty Table\"\n",
    "        else:\n",
    "            for row in output:\n",
    "                outputschema += \"|\".join([str(x) for x in row]) + \"\\n\"\n",
    "        outputschema += \"  foreign keys: \" + \", \".join([f\"{fro} -> {to} ({tab})\" for tab, fro, to in fks]) + \"\\n\"\n",
    "        outputschema += \"\\n\"\n",
    "\n",
    "        # # STYLE 3\n",
    "        # fks = [(tab, fro, to) for _, _, tab, fro, to, *_ in c.execute(f\"PRAGMA foreign_key_list({table})\").fetchall()]\n",
    "        # cols_to_star = [co for _, co, _ in fks]\n",
    "        # columns = [column + (\"*\" if pk or column in cols_to_star else \"\") for _, column, dtype, _, _, pk in c.execute(f\"PRAGMA table_info({table})\").fetchall() ]\n",
    "        # output = c.execute(f\"select * from {table} limit 2\").fetchall()\n",
    "        # outputschema += f\"== {table} ==\\n\"\n",
    "        # for i, column in enumerate(columns):\n",
    "        #     if len(output) == 0:\n",
    "        #         outputschema += f\"{column} ()\"\n",
    "        #     elif len(output) == 1:\n",
    "        #         outputschema += f\"{column} ({output[0][i]})\"\n",
    "        #     else:\n",
    "        #         outputschema += f\"{column} ({output[0][i]}|{output[1][i]})\"\n",
    "        #     outputschema += \"\\n\"\n",
    "        # outputschema += \"\\n\"\n",
    "    return outputschema\n",
    "\n",
    "get_db_context = asyncPrompt(\"get_database_context\", get_database_context)\n",
    "correct_sqlite_error = asyncGPT3Edit(\n",
    "    \"correct_sqlite_error\",\n",
    "    \"Update the query to fix the error (correct the sql query between the ``` marks): [{{ error }}]\",\n",
    "    model_name=\"code-davinci-edit-001\",\n",
    "    temperature=0.0,\n",
    "    )\n",
    "\n",
    "# gpt3_zeroshot_sql = asyncGPT3Prompt(\"gpt3_zeroshot_sql\", \"\"\"\n",
    "# Database Context\n",
    "# {{ db_context }}\n",
    "# SQLite Query for question [{{ question }}]:\n",
    "# ```\n",
    "# \"\"\", stop=\"```\", temperature=0.0)\n",
    "\n",
    "# gpt3_zeroshot_explain_plan = asyncGPT3Prompt(\"gpt3_zeroshot_explain_plan\", \"\"\"\n",
    "# Database Context\n",
    "# {{ db_context }}\n",
    "# SQLite Query for question [{{ question }}]...\n",
    "# 1) First we need to consider\n",
    "# \"\"\", stop=\"```\", temperature=1.0, model_name=\"text-davinci-002\")\n",
    "\n",
    "gpt3_zeroshot_sql_warm = asyncGPT3Prompt(\"gpt3_zeroshot_sql_warm\", \"\"\"\n",
    "Database Context\n",
    "{{ db_context }}\n",
    "SQLite Query for question [{{ question }}]:\n",
    "```\"\"\", stop=\"```\", temperature=0.4, model_name=\"code-davinci-002\")\n",
    "\n",
    "def clean_sql_quick(sql):\n",
    "    sql = sql.strip()\n",
    "    sql = sql.replace(\"\\n\", \"\")\n",
    "    removals = [\"sqlite3\", \"sqlite\", \"sql\", \"SQL\"]\n",
    "    for removal in sorted(removals, key=lambda x: len(x), reverse=True):\n",
    "        if sql.startswith(removal):\n",
    "            sql = sql[len(removal):]\n",
    "    return sql\n",
    "\n",
    "async def get_sql_for_question_multi(db_name, text_in, top_n=5):\n",
    "    db_context = await get_db_context(db_name)\n",
    "    sqls = await asyncio.gather(*[gpt3_zeroshot_sql_warm(db_context=db_context, question=text_in) for _ in range(top_n)])\n",
    "    sqls = list(set([clean_sql_quick(sql) for sql in sqls]))\n",
    "\n",
    "    async def run_sql_for_result(sql):\n",
    "        trials = 0\n",
    "        while trials < 4:\n",
    "            try:\n",
    "                return (sql, get_result(db_name, sql))\n",
    "            except Exception as e:\n",
    "                last_prompt = gpt3_zeroshot_sql_warm.get_prompt(db_context=db_context, question=text_in) + sql + '```'\n",
    "                response = await correct_sqlite_error(error=str(e), input=last_prompt)\n",
    "                try:\n",
    "                    sql = response.split('```')[1]\n",
    "                    sql = clean_sql_quick(sql)\n",
    "                except:\n",
    "                    sql = \"\"\n",
    "                trials += 1\n",
    "        return (sql, None)\n",
    "        \n",
    "    results = await asyncio.gather(*[run_sql_for_result(sql) for sql in sqls])\n",
    "\n",
    "    answers = {json.dumps(res): set() for _, res in results if res is not None}\n",
    "    for sql, res in results:\n",
    "        if res is not None and sql:\n",
    "            answers[json.dumps(res)].add(sql)\n",
    "    if len(answers) == 0:\n",
    "        return \"FAILED TO GENERATE SQL\"\n",
    "\n",
    "    top_answers = sorted(answers.values(), key=len, reverse=True)[0]\n",
    "    return next(iter(top_answers))\n",
    "\n",
    "get_sql_from_text_multi = asyncPrompt(\"get_sql_from_text_multi\", get_sql_for_question_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def row_runner(row, verbose=False):\n",
    "    sql_answers = {\n",
    "        'query_answer': row['query'],\n",
    "        'gpt3_answer': await get_sql_from_text_multi(row['db_id'], row['text_in']),\n",
    "    }\n",
    "    sql_executed = {}\n",
    "    for k, query in sql_answers.items():\n",
    "        newrow = k.split('_')[0]+'_data'\n",
    "        try:\n",
    "            sql_executed[k.split('_')[0]+'_data'] = get_result(row['db_id'], query)\n",
    "        except Exception as e:\n",
    "            sql_executed[k.split('_')[0]+'_data'] = str(e)\n",
    "\n",
    "    if not isinstance(sql_executed['query_data'], list):\n",
    "        print(\"Gold failed to execute\")\n",
    "\n",
    "    execution_equals = {}\n",
    "    for k, v in sql_executed.items():\n",
    "        newrow = k.replace('data', 'is_equal')\n",
    "        if not isinstance(v, list):\n",
    "            execution_equals[newrow] = False\n",
    "        execution_equals[newrow] = v == sql_executed['query_data']\n",
    "\n",
    "    execution_is_superset = {}\n",
    "    for k, v in sql_executed.items():\n",
    "        newrow = k.replace('data', 'is_superset')\n",
    "        if not isinstance(v, list):\n",
    "            execution_is_superset[newrow] = False\n",
    "        if len(v) != len(sql_executed['query_data']):\n",
    "            execution_is_superset[newrow] = False\n",
    "        else:\n",
    "            execution_is_superset[newrow] = all([set(x) >= set(y) for (x, y) in zip(v, sql_executed['query_data'])])\n",
    "    \n",
    "    execution_is_same_set_of_rows = {}\n",
    "    for k, v in sql_executed.items():\n",
    "        newrow = k.replace('data', 'is_same_set_of_rows')\n",
    "        if not isinstance(v, list):\n",
    "            execution_is_same_set_of_rows[newrow] = False\n",
    "        execution_is_same_set_of_rows[newrow] = set(v) == set(sql_executed['query_data'])\n",
    "    return sql_answers | sql_executed | execution_equals | execution_is_superset | execution_is_same_set_of_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# await row_runner(data[1101])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [(i, x) for i, x in enumerate(data) if x['question'] == 'What are the first and last names of the customers with the 10 cheapest invoices?']\n",
    "# thing = random.sample(data, 1)[0]\n",
    "# rowid = random.randint(0, len(data))\n",
    "# thing = data[rowid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(thing['question'])\n",
    "# print(thing['db_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "results = []\n",
    "for i in random.sample(range(len(data)), 50):\n",
    "    thing = data[i]\n",
    "    print(i, thing['question'], thing['db_id'])\n",
    "    result = await row_runner(thing)\n",
    "    result |= {'row_number': i, 'question': thing['question'], 'db_id': thing['db_id']}\n",
    "    results.append(result)\n",
    "    df = pd.DataFrame(results)\n",
    "    print(df['query_is_equal'].sum())\n",
    "    print(df[['gpt3_is_equal', 'gpt3_is_superset', 'gpt3_is_same_set_of_rows']].sum())\n",
    "    time.sleep(10.0)\n",
    "# import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# async def get_prompttext_for_id(row_id):\n",
    "#     db_name, text_in = data[row_id]['db_id'], data[row_id]['question']\n",
    "#     db_context = await get_db_context(db_name)\n",
    "#     return gpt3_zeroshot_sql.get_prompt(db_context=db_context, question=text_in)\n",
    "\n",
    "# print(await get_prompttext_for_id(2566))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_result('products_gen_characteristics', \"SELECT product_name FROM Products WHERE color_code != (SELECT color_code FROM Ref_Colors WHERE color_description = 'white') AND product_category_code NOT IN (SELECT product_category_code FROM Ref_Product_Categories WHERE unit_of_measure = 'Handful');\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.gpt3_is_superset.sum()+(df.gpt3_is_same_set_of_rows.sum()-df.gpt3_is_equal.sum())) / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"trial6.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit ('sketch': pyenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "adcb619b33f588203bb576ea56ee3c20c6d0d8de6f18aca777331501d8e7497b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
