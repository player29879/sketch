{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "# This is a very clear work in progress, just trying to move some code into a place where it can be cleaned later, but for now re-used.\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "PM_SETTINGS = {\n",
    "    \"BOT_TOKEN\": \"5a3556bb2de44a73ab2e5643cb633a6c\",\n",
    "    \"THREAD_ID\": \"default\",\n",
    "    \"DB_PATH\": \"../datasets/nba_sql.db\",\n",
    "    \"LOCAL_HISTORY_DB\": \"sqlite+aiosqlite:///promptHistory.db\",\n",
    "    \"VERBOSE\": True,\n",
    "    \"openai_api_key\": os.environ.get(\"OPENAI_API_KEY\"),\n",
    "}\n",
    "\n",
    "PM_SETTINGS[\n",
    "    \"uri\"\n",
    "] = f\"wss://www.approx.dev/ws/chat?thread_id={PM_SETTINGS['THREAD_ID']}\"\n",
    "\n",
    "\n",
    "async def get_gpt3_response(prompt, temperature=0, stop=None):\n",
    "    if not PM_SETTINGS[\"openai_api_key\"]:\n",
    "        raise Exception(\"No OpenAI API key found\")\n",
    "    # print the prompt if verbose mode\n",
    "    if PM_SETTINGS[\"VERBOSE\"]:\n",
    "        print(prompt)\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {PM_SETTINGS['openai_api_key']}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "    data = {\n",
    "        \"prompt\": prompt,\n",
    "        \"max_tokens\": 500,\n",
    "        \"temperature\": temperature,\n",
    "        \"model\": \"text-davinci-002\",\n",
    "        \"presence_penalty\": 0.4,\n",
    "        \"frequency_penalty\": 0.4,\n",
    "    }\n",
    "    if stop:\n",
    "        data[\"stop\"] = stop\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.post(\n",
    "            \"https://api.openai.com/v1/completions\", headers=headers, json=data\n",
    "        ) as resp:\n",
    "            answer = await resp.json()\n",
    "    if \"choices\" in answer:\n",
    "        return answer[\"choices\"][0][\"text\"]\n",
    "    else:\n",
    "        print(\"Possible error: query returned:\", answer)\n",
    "    return answer.get(\"choices\", [{\"text\": \"\"}])[0][\"text\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await get_gpt3_response(\"Hello, world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [f\"Hi, my name is {n} and I think science is\" for n in [\"Justin\", \"Jen\", \"Jill\", \"James\"]]\n",
    "res = await asyncio.gather(*[get_gpt3_response(p) for p in prompts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.8 seconds in parallel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = [await get_gpt3_response(p) for p in prompts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.9 seconds in serial! Parallel works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit ('sketch': pyenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "adcb619b33f588203bb576ea56ee3c20c6d0d8de6f18aca777331501d8e7497b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
