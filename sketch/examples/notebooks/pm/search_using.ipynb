{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sketch.examples.prompt_machine import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await setup_database(database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.googleapis.com/customsearch/v1?[parameters]\n",
    "import os\n",
    "import requests\n",
    "\n",
    "# LIMITS: 10k/day \n",
    "# also equivalent to ~$50 a day\n",
    "# that's 1 every 8.6s -> or, if burst (2 hours of conversation) -> one every ~0.7 seconds.\n",
    "# hmm, that's not so bad. \n",
    "@prompt\n",
    "async def get_google_response(query):\n",
    "    google_search_api_key = os.environ.get(\"GOOGLE_SEARCH_API_KEY\", None)\n",
    "    google_search_engine_id = os.environ.get(\"GOOGLE_SEARCH_ENGINE_ID\", None)\n",
    "    assert google_search_api_key is not None, \"Must have a GOOGLE_SEARCH_API_KEY (and possibly GOOGLE_SEARCH_ENGINE_ID)\"\n",
    "    assert google_search_engine_id is not None, \"Must have a GOOGLE_SEARCH_ENGINE_ID\"\n",
    "    \n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.get(\n",
    "            \"https://www.googleapis.com/customsearch/v1\",\n",
    "            params={\"key\": google_search_api_key, \"cx\": \"52cad330ac26249b7\", \"q\": query}\n",
    "        ) as resp:\n",
    "            response = await resp.json()\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeper_website_choice = asyncGPT3Prompt(\"deeper_website_choice\",\n",
    "\"\"\"\n",
    "For the question [{{ question }}], the search results are\n",
    "{{ search_results }}\n",
    "In order to answer the question, which three page indices (0-9 from above) should be further investigated? (eg. [2, 7, 9])\n",
    "[\"\"\", stop=\"]\",\n",
    ")\n",
    "\n",
    "import aiohttp\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_text(html):\n",
    "    soup = BeautifulSoup(html, features=\"html.parser\")\n",
    "\n",
    "    for script in soup([\"script\", \"style\"]):\n",
    "        script.extract()\n",
    "\n",
    "    text = soup.get_text()\n",
    "    lines = (line.strip() for line in text.splitlines())\n",
    "    chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "    text = '\\n'.join(chunk for chunk in chunks if chunk)\n",
    "    return text\n",
    "\n",
    "@prompt\n",
    "async def get_more_info_from_webiste(question, url):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.get(url) as resp:\n",
    "            html = await resp.text()\n",
    "    return extract_text(html)[:4000]\n",
    "\n",
    "get_question_answer_from_website = asyncGPT3Prompt(\"get_question_answer_from_website\",\n",
    "\"\"\"\n",
    "For the question [{{ question }}], the website [{{ url }}] was chosen.\n",
    "The possibly truncated text from the website is\n",
    "```\n",
    "{{ text }}\n",
    "```\n",
    "What is the answer to the question, with defense and quotes from the text? (The goal is to be truthful and reliable)\n",
    "\"\"\")\n",
    "\n",
    "@prompt\n",
    "async def get_answer_to_question_based_on_website(question, url):\n",
    "    text = await get_more_info_from_webiste(question, url)\n",
    "    return await get_question_answer_from_website(question=question, url=url, text=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = await get_google_response(\"How many buildings are there in tokyo?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question = \"How many buildings are there in tokyo?\"\n",
    "# search_results = \"\\n\".join([f\"{i}: {x['title']} ({x['snippet']})\" for i, x in enumerate(test[\"items\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_based_answer = asyncGPT3Prompt(\"google_based_answer\",\n",
    "\"\"\"\n",
    "QUESTION AND ANSWER -- Google Search Results Based\n",
    " (The goal is to be truthful and reliable, so if the answer isn't possible it is best to explain the difficulty with answering wrather than trying to answer.\n",
    "  If there is a clear answer (multiple pages agree, and summaries of some pages also agree) then explain the answer and the evidence for it.)\n",
    "QUESTION: {{ question }}\n",
    "For the question [{{ question }}], the search results are\n",
    "====\n",
    "{{ search_results }}\n",
    "====\n",
    "Additionally, 3 pages were explored, and their summaries and answers are:\n",
    "==\n",
    "{{ website_answers }}\n",
    "==\n",
    "What is the answer to the question ({{question}}), with defense and quotes from the results above?\n",
    "\"\"\")\n",
    "\n",
    "@prompt\n",
    "async def google_answer_to_question(question):\n",
    "    raw_results = await get_google_response(question)\n",
    "    search_results = \"\\n\".join([f\"{i}: {x['title']} ({x['snippet']})\" for i, x in enumerate(raw_results[\"items\"])])\n",
    "    next_choices = await deeper_website_choice(question=question, search_results=search_results)\n",
    "    try:\n",
    "        next_choices = [int(x) for x in next_choices.split(\",\")]\n",
    "    except:\n",
    "        next_choices = [0, 1, 2]\n",
    "    urls = [raw_results[\"items\"][x][\"link\"] for x in next_choices]\n",
    "    futures = [get_answer_to_question_based_on_website(question=question, url=url) for url in urls]\n",
    "    # gather seems to fail when inspecting??\n",
    "    # answers = await asyncio.gather(*[get_answer_to_question_based_on_website(question, url) for url in urls])\n",
    "    answers = [await x for x in futures]\n",
    "    return await google_based_answer(question=question, search_results=search_results, website_answers=\"\\n\".join(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await google_answer_to_question(\"What are the tallest 3 bulidings in Tokyo?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit ('sketch': pyenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "adcb619b33f588203bb576ea56ee3c20c6d0d8de6f18aca777331501d8e7497b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
