{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sketch.examples.prompt_machine import *\n",
    "\n",
    "PM_SETTINGS['uri'] = 'ws://localhost:8000/ws/chat?thread_id=default'\n",
    "\n",
    "langresponse = GPT3Prompt(\"inner_conversation\",\n",
    "\"\"\"{% set convosteps = internal_conversation.split('\\n') %}\n",
    "This is a conversation between two internal thoughts (good friends), A and B, of datAI. (both A and B like to talk, and will always respond to silence with a new topic)\n",
    "They are trying to think about the best way to respond through being insightful, interesting, creative, and non-repetitive.\n",
    "They are also trying to be as concise as possible, and to not repeat themselves.\n",
    "A and B do not talk in pleasantries and prefer to stick to details of the topic that is summarized, trying to always come up with creative answers.\n",
    "The current external conversation that datAI is having (summarized) [{{ summary_of_external }}]\n",
    "\n",
    "=== Historical Conversation Sample ===\n",
    "A: it seems as if we could probably respond by asking a clarifying question\n",
    "B: I dunno, that might be too strong, don't we already know the answer? that we can compute it?\n",
    "===\n",
    "\n",
    "Internal Thoughts:\n",
    "{{ internal_conversation }}\n",
    "{% if convosteps[-1:] | length > 0 %}{% if convosteps[-1][0] == 'A' %}B:{% else %}A:{% endif %}{% endif %}\"\"\", stop=\"\\n\"\n",
    ")\n",
    "\n",
    "get_summary_of_conversation = GPT3Prompt(\"summary_of_conversation\",\n",
    "\"\"\"\n",
    "The following is an excerpt from a conversation.\n",
    "{{ conversation }}\n",
    "What is a brief summary of this conversation? (Who is talking, what are their goals, what is expected to happen, etc.)\n",
    "Summary\n",
    "```\n",
    "\"\"\", stop=\"```\")\n",
    "\n",
    "get_conversation_response = GPT3Prompt(\"respond_to_conversation\",\n",
    "\"\"\"\n",
    "The following is an excerpt from an interesting conversation between a human and datAI (a digital data assistant).\n",
    "{{ conversation }}\n",
    "== DatAI has been thinking about how to respond and DatAI's secret internal monologue is ==\n",
    "{{ summary_of_internal }}\n",
    "== end of secret monologue ==\n",
    "What should datAI say? (Note: datAI should not talk about A or B, also datAI never repeats itself)\n",
    "datAI:\n",
    "```\n",
    "\"\"\", stop=\"```\")\n",
    "\n",
    "def step_internal(innermonologue, external_summary):\n",
    "    internal = langresponse(\n",
    "        summary_of_external=external_summary,\n",
    "        internal_conversation=innermonologue\n",
    "    )\n",
    "    if innermonologue.split(\"\\n\")[-1:]:\n",
    "        if (innermonologue.split(\"\\n\")[-1])[0] == \"A\":\n",
    "            innermonologue += \"\\nB:\"+internal\n",
    "        else:\n",
    "            innermonologue += \"\\nA:\"+internal\n",
    "    return \"\\n\".join(innermonologue.split(\"\\n\")[-15:])\n",
    "\n",
    "\n",
    "def response_callback(conversation, internalSummary):\n",
    "    response = get_conversation_response(conversation=conversation, summary_of_internal=internalSummary)\n",
    "    return response\n",
    "\n",
    "\n",
    "async def chatbot(response_callback):\n",
    "    messages = []\n",
    "    innermonologue = \"A: Hello! How can we help?\"\n",
    "    external_summary = \"datAI is a digital data assistant trying to help out a human\"\n",
    "    async with websockets.connect(PM_SETTINGS['uri'], extra_headers={\"Cookie\": f\"Authorization=Bearer {PM_SETTINGS['BOT_TOKEN']}\"}) as ws:\n",
    "        while True:\n",
    "            try:\n",
    "                raw_data = await asyncio.wait_for(ws.recv(), timeout=2.5)\n",
    "                data = json.loads(raw_data)\n",
    "                print(\"log:\", raw_data)\n",
    "                if data.get(\"meta\", False):\n",
    "                    continue\n",
    "                if data.get(\"replay\", False) or data[\"sender\"] == \"datAI\":\n",
    "                    messages.append(data)\n",
    "                    continue\n",
    "                if data[\"message\"] == \"break\":\n",
    "                    break\n",
    "                messages.append(data)\n",
    "            except asyncio.TimeoutError:\n",
    "                # innermonologue = step_internal(innermonologue, external_summary)\n",
    "                continue\n",
    "            await ws.send(json.dumps({\"typing\": True}))\n",
    "            conversation_as_string = \"\\n\".join([f\"{m['sender']}: {m['message']}\" for m in messages])\n",
    "            external_summary = get_summary_of_conversation(conversation_as_string)\n",
    "            # run inner 5 times\n",
    "            for i in range(5):\n",
    "                innermonologue = step_internal(innermonologue, external_summary)\n",
    "            internal_summary = get_summary_of_conversation(innermonologue)\n",
    "            response = response_callback(conversation_as_string, internal_summary)\n",
    "            innermonologue = \"A: Hello! How can we help?\"\n",
    "            await ws.send(json.dumps({\"message\": response}))\n",
    "            await ws.send(json.dumps({\"typing\": False}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let the conversation go, and when composing a response, first send / describe the situation to the \"live conversation\"\n",
    "# then watch it for a little while, summarize, and then compose a response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await chatbot(response_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "langresponse(summary_of_external=\"Steve is trying to learn about NBA statistics.\", internal_conversation=\"A: Hello! How can we help?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit ('sketch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "1a56c398c352595db7d0130f0fc00eb36e63ee8641ddc16c2e5bdd38e08d5e9b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
