{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import websockets\n",
    "import json\n",
    "import asyncio\n",
    "import sqlite3\n",
    "import requests\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "oopenai_api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "BOT_TOKEN = \"5a3556bb2de44a73ab2e5643cb633a6c\"\n",
    "THREAD_ID = \"default\"\n",
    "DB_PATH = '../datasets/nba_sql.db'\n",
    "uri = f\"ws://localhost:8000/ws/chat?thread_id={THREAD_ID}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gpt3_response(prompt, stop=None):\n",
    "    headers = {\"Authorization\": f\"Bearer {oopenai_api_key}\", \"Content-Type\": \"application/json\"}\n",
    "    data = {\"prompt\": prompt, \"max_tokens\": 500, \"temperature\": 0, \"model\": \"text-davinci-002\"}\n",
    "    if stop:\n",
    "        data[\"stop\"] = stop\n",
    "    response = requests.post(\"https://api.openai.com/v1/completions\", headers=headers, json=data)\n",
    "    return response.json()[\"choices\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def chatbot_messages():\n",
    "    uri = f\"ws://localhost:8000/ws/chat?thread_id={THREAD_ID}\"\n",
    "    messages = []\n",
    "    async with websockets.connect(uri, extra_headers={\"Cookie\": f\"Authorization=Bearer {BOT_TOKEN}\"}) as ws:\n",
    "        while True:\n",
    "            try:\n",
    "                raw_data = await asyncio.wait_for(ws.recv(), timeout=0.5)\n",
    "                data = json.loads(raw_data)\n",
    "                if data.get(\"replay\", False):\n",
    "                    messages.append(data)\n",
    "                    continue\n",
    "            except:\n",
    "                break\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jinja2 import Template\n",
    "\n",
    "verbose = True\n",
    "# https://zetcode.com/python/jinja/\n",
    "class GPT3Prompt:\n",
    "    def __init__(self, prompt_template_string, stop=None):\n",
    "        self.prompt_template = Template(prompt_template_string)\n",
    "        self.stop = stop\n",
    "\n",
    "    def get_prompt(self, **kwargs):\n",
    "        return self.prompt_template.render(**kwargs)\n",
    "\n",
    "    def execute(self, **kwargs):\n",
    "        prompt = self.get_prompt(**kwargs)\n",
    "        if verbose:\n",
    "            print(\"=\"*80)\n",
    "            print(f\"prompt:\\n{prompt}\")\n",
    "        response = get_gpt3_response(prompt, self.stop)\n",
    "        if verbose:\n",
    "            print(\"-\"*80)\n",
    "            print(f\"response:\\n{response}\")\n",
    "            print(\"=\"*80)\n",
    "        return response\n",
    "\n",
    "    def __call__(self, **kwargs):\n",
    "        return self.execute(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isSQLyn = GPT3Prompt(\n",
    "\"\"\"\n",
    "The following is a conversation with a data expert (datAI). \n",
    "In order to respond to the prompt, should the datAI use SQL or just say something friendly in response?\n",
    "===\n",
    "{% for message in messages %}\n",
    "{{ message[\"sender\"] }}: {{ message[\"message\"] }}\n",
    "{% endfor %}\n",
    "===\n",
    "The datAI should use SQL to answer the question (y/n):\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlExecutor = GPT3Prompt(\n",
    "\"\"\"\n",
    "The following is a conversation with a data expert (datAI). In order to be accurate, datAI would like to use SQL. \n",
    "===\n",
    "{% for message in messages %}\n",
    "{{ message[\"sender\"] }}: {{ message[\"message\"] }}\n",
    "{% endfor %}\n",
    "===\n",
    "|| Database Context ||\n",
    "{{ database_context }}\n",
    "||||||||||||||||||||||\n",
    "{% if previousAttempt %}\n",
    "{{ previousAttempt }}\n",
    "{% endif %}\n",
    "The SQL query that datAI would like to execute is:\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gotAValidSQLResponse = GPT3Prompt(\n",
    "\"\"\"\n",
    "===\n",
    "{% for message in messages %}\n",
    "{{ message[\"sender\"] }}: {{ message[\"message\"] }}\n",
    "{% endfor %}\n",
    "===\n",
    "In order to answer a question (above), a data expert (datAI) executed the following SQL query:\n",
    "{{ sql }}\n",
    "And the result of the execution was:\n",
    "{{ result }}\n",
    "===\n",
    "Is the result of the SQL query correct and answer the users question? (y/n):\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "composeDataDrivenAnswer = GPT3Prompt(\n",
    "\"\"\"\n",
    "The following is a conversation with a data expert (datAI). In order to be accurate, the data expert used a database (queried with SQL).\n",
    "===\n",
    "{% for message in messages %}\n",
    "{{ message[\"sender\"] }}: {{ message[\"message\"] }}\n",
    "{% endfor %}\n",
    "===\n",
    "The query and response:\n",
    "{{ sql }}\n",
    "{{ result }}\n",
    "===\n",
    "What should datAI say in response to the last message?\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neededHelpButStillFriendly = GPT3Prompt(\n",
    "\"\"\"\n",
    "The following is a conversation with a friendly chatbot (datAI, a data expert), who loves basketball.\n",
    "The dataAI tried to run some SQL, but failed to get a good response to the question, \n",
    "and now wants to ask a clarifying question so that it can query the database better to help the user...\n",
    "===\n",
    "{% for message in messages %}\n",
    "{{ message[\"sender\"] }}: {{ message[\"message\"] }}\n",
    "{% endfor %}\n",
    "datAI:\"\"\", stop=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "friendlyChatbot = GPT3Prompt(\n",
    "\"\"\"\n",
    "The following is a conversation with a friendly chatbot (datAI, a data expert), who loves basketball.\n",
    "The response will never contain a data response unless it has proof in the form of executed SQL. \n",
    "datAI does not respond with guesses, so will ask questions to clarify the users intent to help it formulate a SQL query.\n",
    "===\n",
    "{% for message in messages %}\n",
    "{{ message[\"sender\"] }}: {{ message[\"message\"] }}\n",
    "{% endfor %}\n",
    "datAI:\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkIfNeedsSQL = GPT3Prompt(\n",
    "\"\"\"\n",
    "The following is a conversation with a friendly chatbot (datAI, a data expert), who loves basketball.\n",
    "Does the following statement contain any attempt at factual information that would exist in a database?\n",
    "Statement: {{ statement }}\n",
    "===\n",
    "y/n:\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(DB_PATH) \n",
    "c = conn.cursor()\n",
    "# execute a sql query to get all the tables and the columns in the tables\n",
    "c.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "outputschema = \"\"\n",
    "for table, in c.fetchall():\n",
    "    outputschema += table + \"||[\"\n",
    "    c.execute(f\"PRAGMA table_info({table})\")\n",
    "    for _, column, dtype, *_ in c.fetchall():\n",
    "        outputschema += f\"{column}:{dtype},\"\n",
    "    outputschema += \"]\\n\"\n",
    "database_context = outputschema\n",
    "\n",
    "def example_promptchain(messages):\n",
    "    answer = friendlyChatbot(messages=messages[-5:])\n",
    "    response = checkIfNeedsSQL(statement=answer).strip()[:1]\n",
    "    trials = 0\n",
    "    if response != \"n\":\n",
    "        previousAttempt = None\n",
    "        while trials < 3:\n",
    "            sqlresponse = sqlExecutor(messages=messages[-5:], previousAttempt=previousAttempt, database_context=database_context)\n",
    "            try:\n",
    "                conn = sqlite3.connect(DB_PATH) \n",
    "                c = conn.cursor()\n",
    "                c.execute(sqlresponse)\n",
    "                res = str(c.fetchall())[:500]\n",
    "            except Exception as e:\n",
    "                res = f\"Error executing SQL {e}\"\n",
    "            validSQL = gotAValidSQLResponse(messages=messages[-5:], sql=sqlresponse, result=res).strip()[:1]\n",
    "            if validSQL != \"n\":\n",
    "                return composeDataDrivenAnswer(messages=messages[-5:], sql=sqlresponse, result=res)\n",
    "            trials += 1\n",
    "            print(\"I tried and failed... trying again\")\n",
    "            previousAttempt = f\"{sqlresponse}\\n{res[:100]}\"\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "async def chatbot():\n",
    "    messages = []\n",
    "    async with websockets.connect(uri, extra_headers={\"Cookie\": f\"Authorization=Bearer {BOT_TOKEN}\"}) as ws:\n",
    "        while True:\n",
    "            try:\n",
    "                raw_data = await asyncio.wait_for(ws.recv(), timeout=0.5)\n",
    "                data = json.loads(raw_data)\n",
    "                print(\"log:\", data['message'])\n",
    "                if data.get(\"replay\", False) or data[\"sender\"] == \"datAI\":\n",
    "                    messages.append(data)\n",
    "                    continue\n",
    "                if data[\"message\"] == \"break\":\n",
    "                    break\n",
    "                if data.get(\"meta\", False):\n",
    "                    continue\n",
    "                messages.append(data)\n",
    "            except asyncio.TimeoutError:\n",
    "                # not sure why I'm doing this, it felt important to have an \"infinite\" loop...\n",
    "                continue\n",
    "            response = example_promptchain(messages)\n",
    "            await ws.send(json.dumps({\"message\": response}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await chatbot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# messages = await chatbot_messages()\n",
    "# response = example_promptchain(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit ('sketch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "1a56c398c352595db7d0130f0fc00eb36e63ee8641ddc16c2e5bdd38e08d5e9b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
